
\documentclass[11pt]{article}

\usepackage[latin1]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{url}
\usepackage[breaklinks=true,hyperref]{hyperref}
\usepackage{amssymb}
\usepackage[dvips]{color}
\usepackage{epsfig}
\usepackage{mathrsfs}
\usepackage{comment}

\include{header}


\begin{document}

\title{{\bf Efficient Inference in Probabilistic Computing} \\ M.Eng Propsal}
\author{Jeff Wu}
%\address{}
%\email{}
\date{}
\maketitle
%
%\begin{center} \begin{LARGE} {\sc \bf Title} \vs{6}

%{\sc M.Eng Proposal} \vs{9}

%\end{LARGE} { \Large \textsc{Jeff Wu}}

%\end{center}

\begin{abstract}
\end{abstract}

\section{Introduction}

Probabilistic programming languages are generalizations of programming languages, in which procedures are replaced with random procedures that induce distributions.  Probabilistic computing thus allows for easy description and manipulation of probability distributions, letting one describe classical AI models in compact ways.  

A core operation of probabilistic programming languages is inference, which is, in general, a difficult computational problem \cite{?}.  However, Markov chain Monte Carlo (MCMC) methods converge quite quickly to the posterior distribution for a large class of inference problems.  Much effort has been devoted to studying in which cases this inference is efficient, and how to make it so.  

% introduction: restate goals from above, of course including which research direction (parallelism; noise variables; connections to deterministic algorithms like sorting) we actually did


%INTRO
%build pcp engine which i understand well
%tested on variety of problems
%study tractability of inference on other harder problems
%do performance engineering / parallelism

%write-up spec of language
%write-up test cases

%write mixture-model

\subsection{subsection}


\section{Language description}

\subsection{Values and XRPs}

A {\bf value} is a valid binding for a variable, in our language.  For example, integers, floats, and booleans are valid values, as are procedures --- functions which take in arguments and return values.  

Our language allows for definition of something more general than random procedures, while retaining the ability to perform inference.   It allows for what we call an Exchangeable Random Procedure (XRP).  

An XRP is like a random procedure, except that different applications of it are not guaranteed to be independent.  An XRP is allowed to maintain an internal state, which can be modified.  However, an XRP must maintain the exchangeability condition, which says that applications of the XRP gives an exchangeable sequence of random variables.  

The exchangeable sequence 



\subsection{Expressions and Environments}

Expressions are syntactic building blocks which are evaluated into values.  An expression may be one of the following:
\begin{itemize}
\item Atomic expressions:
\begin{itemize}
\item A value itself.
\item A variable name.
\end{itemize}
\item Non-atomic expressions
\begin{itemize}
\item An application of an expression to a list of argument expressions.
\item A function, consisting of some variable arguments, and a body expression.
\item An if statement, consisting of a branching expression, and two child expressions.
\item An operator statement, consisting of an operator (e.g. == , $<$ , + , $\times$ , {\tt AND}, {\tt OR}, {\tt NOT}) and a list of argument expressions.
% \item A switch statement, consisting of a branching expression, and a list of child expressions
\end{itemize}
\end{itemize}

Expressions are evaluated relative to an {\bf environment}, in which variable names may be bound to values.  

Evaluation happens recursively, resulting in return values.  When an invalid expression is given (e.g. the first expression in an application does not result in an XRP or procedure, or we call the equality operator with three arguments), an error is thrown.  

\subsection{Directives}

There are four primitive operations, called {\bf directives}, which the language supports.  They are:

\begin{enumerate}
\item {\tt assume(name, expression)}

Binds {\tt name}, a string name, to the expression {\tt expression}.

\item {\tt observe(expression, value)} : 

Observes the expression {\tt expression} to have value {\tt value}.

\item {\tt sample(expression)} : 

Evaluates to sample a value for the expression {\tt expression}.

\item {\tt infer()} : 

Runs a single step of the Markov Chain.

\end{enumerate}


% if we observe(blah, true), observe(blah, false)

%    - language definition with examples
%                - XRPs: what they are, and how to add them


%
%        - test cases. for each test case, include:

%            - a couple paragraphs and a figure explaining the purpose of the test
%                - analytical calculations or invariants showing what you'd expect if the interpreter was behaving correctly
%                - code for the program
%                - results, compared to the analytical section
\subsection{Architecture of inference}

We now describe the way in which inference is implemented.  

The idea is to run Metropolis-Hastings on the space of all possible executions of the program.  

Our proposal density does the following:   
\begin{enumerate}
\item Pick, at random, one of the random choices made, at any point in the program's execution history.  Rerun the entire program, using the same randomness.  
\item When we reach the random choice chosen above, resample a value for it.  If this causes us to evaluate different branches of the code (or to evaluate procedures called with different arguments), simply run these new branches, and also undo the evaluation of previously-evaluated branches which are no longer evaluated.   
\item For all observations, use the outermost noise to force.  
\end{enumerate}

Notice that if there is no noise in our observations, this algorithm does not necessarily mix in finite time.  

Consider the following example: \\




Some executions are more likely than others, and so 

Here pseudocode for a single iteration:

\begin{verbatim}
  stack = globals.db.random_stack()
  (xrp, val, prob, args) = globals.db.get(stack)

  old_p = globals.db.prob()
  old_to_new_q = - math.log(globals.db.count)

  globals.db.save()

  globals.db.remove(stack)
  new_val = xrp.apply(args)

  if val == new_val:
    globals.db.insert(stack, xrp, new_val, args)
    return
  globals.db.insert(stack, xrp, new_val, args)

  rerun(False)
  new_p = globals.db.prob() 
  new_to_old_q = -math.log(globals.db.count) 
  old_to_new_q += globals.db.eval_p 
  new_to_old_q += globals.db.uneval_p 
  if old_p * old_to_new_q > 0:
    p = random.random()
    if new_p + new_to_old_q - old_p - old_to_new_q < math.log(p):
      globals.db.restore()
  globals.db.save()
\end{verbatim}
% : MH on random worlds
%            - pseudcode, reflecting what you learned (beyond what was in the AISTATS paper)
%            - discuss eval, uneval, XRPs with state, mem as an example, etc
%        - [[whatever focused experiments/results we come up with]]

%\cite{Fagin1}:  

\pagebreak

\section{Test Cases}

In order to ensure the language was working properly, a suite of test cases was developed.  

One of the primary techniques used for testing was ``following the prior", using the function {\tt follow\_prior(variable, niters, burnin)}.  To follow the prior, we draw {\tt niters} samples from the prior, and run each of them {\tt burnin} steps in the random walk.  We then view the resulting distribution on {\tt variable}.  % generalize this to view joints on many variables

Here are some of the more illustrative and interesting test cases.


\subsection{Testing a tricky coin}

Consider the following scenario:  There is a coin that is fair with probability 50\%.  The rest of the time, its weight is drawn uniformly from the interval [0, 1].  The coin is flipped, and we observe it to be heads {\tt nheads} times.  We then infer the posterior probability that the coin was fair. 

\begin{small}
\begin{verbatim}
>>>  noise_level = .001
>>>  nheads = 1
>>>  
>>>  assume('weight', beta(1, 1))
>>>  assume('tricky-coin', function([], bernoulli('weight')))
>>>  assume('fair-coin', function([], bernoulli(0.5)))
>>>  assume('is-fair', bernoulli(0.5))
>>>  assume('coin', ifelse('is-fair', 'fair-coin', 'tricky-coin')) 
>>>
>>>  for i in xrange(nheads):
>>>    observe(bernoulli_noise(apply('coin'), noise_level), True)
>>>
>>>  follow_prior('is-fair', 10000, 1000)
\end{verbatim}
\end{small}

% could change to if fair, weight = blah...
% the way it's coded matters.

We should be able to predict the results of running this program for different values of {\tt nheads}.  First we compute the probability that the coin comes up heads $n$ times, given that it is tricky.  The probability is simply $\beta(1, n + 1) = \frac{1}{n +1}$.  Thus the probability the coin is fair (not tricky), given it came up heads $n$ times, is, by Baye's law $$\frac{\frac{1}{2} \cdot \frac{1}{2^n}}{\frac{1}{2} \cdot \frac{1}{n+1} + \frac{1}{2} \cdot \frac{1}{2^n}} = \frac{n+1}{ 2^n + n+1}.$$

Here are our results, when running {\tt follow\_prior('is-fair', 10000, 1000)}, for the percentage of times the coin was fair:  

\begin{center}
\begin{tabular}{|c | c| c |} \hline
{\tt nheads} & Predicted & Actual \\ \hline
0 & 0.5 & 0.4982\\ \hline
1 & 0.5 & 0.4934 \\ \hline
2 & 0.4286 &  0.4289 \\ \hline
3 & 0.3333 &  0.3346 \\ \hline
4 & 0.2381 &  0.2712 \\ \hline
5 & 0.1579 &  0.2528 \\ \hline
\end{tabular}
\end{center}

As {\tt nheads} grows, we should expect the mixing time to grow.  This is because 
\subsection{Bayes nets}

We first test that inference works, by considering a number of test cases.  A classic inference problem which is well understood, is inference in Bayesian networks.  Bayesian networks are incredibly easy to describe in our language.  Here are some simple examples of inference giving the correct answer in a Bayesian network.

\subsubsection{Sprinkler net}

Let's start with a simple example, to get familiar with our language.   Here's a definition of a bayesian network with just two nodes.

\begin{small}
\begin{verbatim}
>>> assume('cloudy', bernoulli(0.5))
>>> assume('sprinkler', ifelse('cloudy', bernoulli(0.1), bernoulli(0.5)))
\end{verbatim}
\end{small}

\noindent We then observe that the sprinkler is on.  Worlds in which the sprinkler is on are weighted as 100 times more likely than ones in which the sprinkler is off.  

\begin{small}
\begin{verbatim}
>>> noise_level = .01
>>> sprinkler_ob = observe(bernoulli_noise('sprinkler', noise_level), True)
\end{verbatim}
\end{small}

\noindent Now, let's try inferring the weather.  We follow the prior 10000 times, going 50 steps each time.  

\begin{small}
\begin{verbatim}
>>> follow_prior('cloudy', 10000, 50)}
{False: 0.82010000000000005, True: 0.1799}
\end{verbatim}
\end{small}

This is close to the value of $\frac{5}{6} = 0.8\overline{333}$ False, which is what we'd get if there was noise in our observation.  However, there is still a number of worlds in which the sprinkler was actually on.  In those worlds, the weather was 50/50.  Thus we should've expect the answer to be on the order of 0.01 lower.  \vspace{6 pt}

Now, let's suppose we didn't observe the sprinkler being on, after all.

% Part of the error is because of the noise.  

\begin{small}
\begin{verbatim} 
>>> forget(sprinkler_ob)
\end{verbatim}
\end{small}

\noindent So it should be the case that it's cloudy exactly half the time.

\begin{small}
\begin{verbatim}
>>> follow_prior('cloudy', 10000, 50)}
{False: 0.50429999999999997, True: 0.49569999999999997}
\end{verbatim}
\end{small}

\noindent  Now, we re-observe the sprinkler to be on.  This time, we are much more sure.

\begin{small}
\begin{verbatim}
>>> noise_level = .001
>>> sprinkler_ob = observe(bernoulli_noise('sprinkler', noise_level), True)
>>> follow_prior('cloudy', 10000, 50)}
{False: 0.83999999999999997, True: 0.16}
\end{verbatim}
\end{small}

\noindent We see that our answer is even closer to the value of $\frac{5}{6} = 0.8\overline{333}$ False, now.

\subsubsection{Alarm net}

Here's a more complicated Bayesian network, which is given as an example in the classic AI textbook Artificial Intelligence (A Modern Approach).  
\begin{center} \includegraphics{burglary.png} \end{center}

\noindent Let's define this Bayesian network.

\begin{small}
\begin{verbatim}
>>> assume('burglary', bernoulli(0.001))
>>> assume('earthquake', bernoulli(0.002))
>>> assume('alarm', ifelse('burglary', ifelse('earthquake', bernoulli(0.95), bernoulli(0.94)), \
...                                    ifelse('earthquake', bernoulli(0.29), bernoulli(0.001))))
>>> assume('johnCalls', ifelse('alarm',  bernoulli(0.9), bernoulli(0.05)))
>>> assume('maryCalls', ifelse('alarm',  bernoulli(0.7), bernoulli(0.01)))
\end{verbatim}
\end{small}

\noindent Let's try a couple inference problems.

\begin{small}
\begin{verbatim}
>>> follow_prior('alarm', 1000, 100) # should give 0.002516 True
{False: 0.99739999999999995, True: 0.0025999999999999999}
>>>
>>> noise_level = .001
>>> mary_ob = observe(bernoulli_noise('maryCalls', noise_level), True)
>>> follow_prior('johnCalls', 1000, 100) # should give 0.177577 True
{False: 0.91620000000000001, True: 0.083799999999999999}
>>>
>>> forget(mary_ob)
>>> burglary_ob = observe(bernoulli_noise(negation('burglary'), noise_level), True)
>>> follow_prior('johnCalls', 1000, 100) # should give 0.051343 True
{False: 0.94710000000000005, True: 0.052900000000000003}
\end{verbatim}
\end{small}

The first and third inferences were on the mark, but the second one was off by a factor of two!   The explanation is that Mary calls very rarely calls.  Indeed, she only calls about 0.01 of the time, since the alarm almost never sounds.  This is rare enough that our observation that she called is reasonably likely to be wrong.  In worlds where she doesn't call, John also tends not to call, thus accounting for the large dip. \vspace{6 pt}

To verify that this is the explanation, we can alter the probabilities so that Mary calling is more likely.  Here is an example of this being done.

\begin{small}
\begin{verbatim}
>>> reset()
>>>
>>> assume('burglary', bernoulli(0.1))
>>> assume('earthquake', bernoulli(0.2))
>>> assume('alarm', ifelse('burglary', ifelse('earthquake', bernoulli(0.95), bernoulli(0.94)), \
...                                    ifelse('earthquake', bernoulli(0.29), bernoulli(0.10))))
>>> assume('johnCalls', ifelse('alarm',  bernoulli(0.9), bernoulli(0.5)))
>>> assume('maryCalls', ifelse('alarm',  bernoulli(0.7), bernoulli(0.1)))
>>>
>>> follow_prior('alarm', 1000, 100) # should give 0.218400 True
{False: 0.77959999999999996, True: 0.22040000000000001}
>>>
>>> noise_level = .001
>>> mary_ob = observe(bernoulli_noise('maryCalls', noise_level), True)
>>> follow_prior('johnCalls', 1000, 100) # should give 0.764681 True
{False: 0.2432, True: 0.75680000000000003}
>>>
>>> forget(mary_ob)
>>> burglary_ob = observe(bernoulli_noise(negation('burglary'), noise_level), True)
>>> follow_prior('johnCalls', 1000, 100) # should give 0.561333 True
{False: 0.44290000000000002, True: 0.55710000000000004}
\end{verbatim}
\end{small}

\noindent Success!


\subsection{Testing xor}

\noindent Consider the following program, where we simply draw two booleans {\tt a} and {\tt b}, and observe that their xor is {\tt True}:

\begin{small}
\begin{verbatim}
>>> p, q = 0.6, 0.4
>>> noise_level = .01
>>>
>>> assume('a', bernoulli(p))
>>> assume('b', bernoulli(q))
>>> assume('c', (var('a') & ~var('b')) |(~var('a') & var('b')))
>>>
>>> follow_prior('a', 10000, 100) # should be 0.60 True
{False: 0.3977, True: 0.60229999999999995}
>>>
>>> xor_ob = observe(bernoulli_noise('c', noise_level), True)
>>> follow_prior('a', 10000, 100) # should be 0.69 True
{False: 0.3342, True: 0.66579999999999995}
\end{verbatim}
\end{small}



This second inference is significantly off, and it's not the case that our observation is particularly unlikely.  Here, the burn-in was not enough.  Notice that in order to mix, the program must walk over states which contradict the observed values.  

Suppose we are in the state {\tt \{a:True, b:True\}}.  Then, the random walk is highly discouraged from entering either of the two adjacent states {\tt \{a:True, b:False\}} and {\tt \{a:False, b:True\}}, since worlds in which {\tt a$\oplus$b} is {\tt False} are weighted against, by a factor of 100.  

Let's estimate the amount of burn-in it should take for this random walk to mix.  Suppose we are in a state where {\tt a$\oplus$b} is {\tt True}.  About half the time, we will attempt to enter one of the two adjacent states (the other half of the time, we will keep the same value for that flip).  Entering this state will occur with probability roughly $\frac{1}{100}$.  Once we are in such a state, we are given an opportunity to enter either of the two {\tt a$\oplus$b} being {\tt True} states, so we have successfully mixed.  

Thus we can roughly model this as having a $\frac{1}{200}$ chance of mixing properly, for each iteration.  Thus if we have a burn-in of $200 \cdot x$, there is roughly a $1 - \frac{1}{e^x}$ chance of mixing.  Here are empirical results of {\tt burnin} against {\tt follow\_prior('a', 10000, burnin)} results:

\begin{center}
\begin{tabular}{|c | c|} \hline
{\tt burnin} & {\tt follow\_prior('a', 10000, burnin)} percentage {\tt True}  \\ \hline
100 &  0.66579999999999995 \\ \hline
200 &  0.67869999999999997 \\ \hline
300 &  0.68200000000000005 \\ \hline
400 &  0.68489999999999995 \\ \hline
500 &  0.68759999999999999 \\ \hline
\end{tabular}
\end{center}

These results are slightly better than our prediction, but confirm the overall phenomenon.  Because of the noise, we can't expect it to ever converge to exactly 0.69.  Instead, we may hope for it to converge to something like $0.01 \cdot 0.60 + 0.99 \cdot 0.69 = 0.6891$.  


\subsection{Testing a decaying atom}

Suppose we are observing a radioactive atom in discrete time intervals, e.g. we look at it each second.  Each time we look at the atom, there is some chance that it 

Suppose there is an atom whose decay rate we don't know.  Our prior over decay rates is uniform 

\begin{small}
\begin{verbatim}
>>> assume('decay', beta(1, 1)) 
>>> assume('geometric', function('x', ifelse(bernoulli('decay'), 'x', apply('geometric', var('x') + 1))))
>>> observe(bernoulli_noise(apply('geometric', 0) == 10, .01), True)
  print get_pdf(follow_prior('decay', 100, 100), 0, 1, .1) 

\end{verbatim}
\end{small}

\subsection{Testing mem}

Here, we test that the memoization procedure works.  

\noindent Let's first write the fibonacci function, in the naive way:

\begin{small}
\begin{verbatim}
>>> fibonacci_expr = function('x', ifelse(var('x')<=1, 1, \
...                  apply('fibonacci', var('x')-1) + apply('fibonacci', var('x')-2)))
>>> assume('fibonacci', fibonacci_expr)
\end{verbatim}
\end{small}

\noindent Of course, evaluating fibonacci in this manner is an exponential time operation:

\begin{small}
\begin{verbatim}
>>> t = time(); sample(apply('fibonacci', 20)); time() - t
10946
1.76103687286
\end{verbatim}
\end{small}

\noindent Mem is an XRP which, when applied to (possibly probabilistic) functions, returns a version of the function which is memoized.  That is, function calls are remembered, so that if a function is called with the same arguments, it does not need to recompute.  Here is an example of mem being used.

\begin{small}
\begin{verbatim}
>>> assume('bad_mem_fibonacci', mem('fibonacci'))
>>>
>>> t = time(); sample(apply('bad_mem_fibonacci', 20)); time() - t
10946
1.90201187134
>>> t = time(); sample(apply('bad_mem_fibonacci', 20)); time() - t
10946
0.00019097328186
\end{verbatim}
\end{small}

\noindent Notice that the second call to this mem'd fibonacci is much faster, since mem remembers the value.  However, the first call is just as slow as before.  Since Fibonacci is recursive, we really want to memoize all the recursive subcalls as well.  The canonical introduction to dynamic programming shows how Fibonacci can be computed in linear time this way.  We can write the program easily:

\begin{small}
\begin{verbatim}
>>> mem_fibonacci_expr = function('x', ifelse(var('x')<=1, 1, \
...                    apply('mem_fibonacci', var('x')-1) + apply('mem_fibonacci', var('x')-2)))
>>> assume('mem_fibonacci', mem(mem_fibonacci_expr))
>>>
>>> t = time(); sample(apply('mem_fibonacci', 20)); time() - t
10946
0.0271570682526
>>> t = time(); sample(apply('mem_fibonacci', 20)); time() - t
10946
0.000293016433716
\end{verbatim}
\end{small}

\subsection{Testing DPMem}

Let's now implement the Dirichlet process.  

\begin{small}
\begin{verbatim}
>>> sticks_expr = mem(function('j', beta(1, 'concentration2')))
>>> atoms_expr = mem(function('j', apply('basemeasure2')))
>>> loop_body_expr = function('j', ifelse(bernoulli(apply('sticks', 'j')), apply('atoms', 'j'), \
...                  apply(apply('loophelper', ['concentration2', 'basemeasure2']), var('j')+1)))
>>> loop_expr = apply(function(['sticks', 'atoms'], loop_body_expr), [sticks_expr , atoms_expr])
>>> assume('loophelper', function(['concentration2', 'basemeasure2'], loop_expr))
>>> assume( 'DP', function(['concentration', 'basemeasure'], \
...                        apply(apply('loophelper', ['concentration', 'basemeasure']), 1)))
\end{verbatim}
\end{small}

We can now use the Dirichlet process to create something we call DPmem.  DPmem is a generalization of mem which sometimes returns memoized values, and sometimes resamples new values.  

\begin{small}
\begin{verbatim}
  """DEFINITION OF DPMEM"""
  restaurants_expr = mem(function('args', apply('DP', ['alpha', function([], apply('proc', 'args'))])))
  assume('DPmem', function(['alpha', 'proc'], function('args', apply(restaurants_expr, 'args'))))


  """TESTING DPMEM"""

  concentration = 1 # when close to 0, just mem.  when close to infinity, sample 
  assume('DPmemflip', apply('DPmem', [concentration, function(['x'], bernoulli(0.5))]))
  print [sample(apply('DPmemflip', 5)) for i in xrange(10)]

  print "\n TESTING GAUSSIAN MIXTURE MODEL\n"
  assume('concentration', gaussian(1, 0.2)) # use vague-gamma? 
  assume('expected-mean', gaussian(0, 1)) 
  assume('expected-variance', gaussian(0, 1))
  assume('gen-cluster-mean', gaussian(0, 1))
  assume('get-datapoint', mem( function(['id'], gaussian('gen-cluster-mean', 1.0))))
  assume('outer-noise', gaussian(1, 0.2)) # use vague-gamma?

  observe(gaussian(apply('get-datapoint', 0), 'outer-noise'), 1.3)
  observe(gaussian(apply('get-datapoint', 0), 'outer-noise'), 1.2)

  t = time()
  print format(get_pdf(follow_prior('expected-mean', 100, 30), -4, 4, .5), '%0.2f')
  print 'time taken', time() - t

  #concentration = 1
  #uniform_base_measure = uniform_no_args_XRP(2)
  #print [sample(apply('DP', [concentration, uniform_base_measure])) for i in xrange(10)]
  #expr = beta_bernoulli_1()

\end{verbatim}
\end{small}


DPmem can be used, for example, to do mixture modeling.  The idea is that we should sometimes


\pagebreak

\begin{thebibliography}{99}

%\bibitem[1]{Fagin1} Fagin, R.  {\em Generalized first-order spectra and polynomial-time recognizable sets}. Complexity of Computation, ed. R. Karp, SIAM-AMS Proceedings 7, 1974, pp. 43--73. 


\end{thebibliography}

\end{document}

